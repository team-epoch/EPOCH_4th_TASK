# Week2 Reading Task


## **ğŸ“˜Â Title**

> â„¹ï¸Â *APA. ì¸ìš© ë°©ì‹ ê¶Œê³ *
> Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. In F. Pereira, C. J. C. Burges, L. Bottou, & K. Q. Weinberger (Eds.), Advances in Neural Information Processing Systems (Vol. 25, pp. 1097â€“1105). Curran Associates, Inc.

---


## **ğŸ“–Â Abstract**

> â„¹ï¸Â *ë³¸ì¸ì˜ ë°©ì‹ìœ¼ë¡œ ì¬í•´ì„ í•´ì£¼ì„¸ìš”. ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì€ ê¸ˆí•©ë‹ˆë‹¤.*
> ëŒ€ê·œëª¨ CNNì„ ImageNetì— í•™ìŠµ. ì…ë ¥ì€ 224Ã—224. 5ê°œ í•©ì„±ê³±ì¸µ(convolutional layers)ê³¼ 3ê°œ ì™„ì „ì—°ê²°ì¸µ(fully connected layers). ReLUë¡œ ë¹ ë¥¸ í•™ìŠµ. GPU ê¸°ë°˜ í•©ì„±ê³± ìµœì í™”. FC ì¸µì— drop out ì ìš©. ILSVRC-2010ì—ì„œ Top-1 37.5% Top-5 17.0%. 2012 ëŒ€íšŒ ë³€í˜• ëª¨ë¸ Top-5 15.3%. ì´ì „ ê¸°ë²• ëŒ€ë¹„ í° ê°œì„ . 

---


## **ğŸ“šÂ Background**

> â„¹ï¸Â *ë…¼ë¬¸ì˜ ì£¼ì œì™€ ê´€ë ¨ëœ ê¸°ì¡´ ì—°êµ¬ë“¤ ë° ë°°ê²½ ì§€ì‹ì„ ì •ë¦¬*
> 
> 
> **ğŸ“Â Related Work 1**
> ì†Œê·œëª¨ ë°ì´í„°ì™€ manual feature-engineering ì¤‘ì‹¬ì˜ ì ‘ê·¼ì´ ì¼ë°˜ì ì´ì—ˆìŒ. SIFTì™€ Fisher Vectorê°€ ê°•ë ¥í•œ ê¸°ì¤€ì„ ì´ì—ˆìŒ. ì´ ê¸°ì¤€ì„ ì€ ILSVRC-2012ì—ì„œ Top-5 26.2%ë¥¼ ê¸°ë¡. 
> **ğŸ“Â Related Work 2**
> CNNì€ local connectivityì™€ weight sharingìœ¼ë¡œ ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì ì„. ê·¸ëŸ¬ë‚˜ ëŒ€ê·œëª¨ í•™ìŠµì—” ì—°ì‚°ëŸ‰ì´ ë³‘ëª©ì´ì—ˆìŒ. ëŒ€í˜• ë°ì´í„°ì™€ GPUê°€ ì œì•½ ì™„í™”í•¨. ë¹„ì „ ì»¤ë®¤ë‹ˆí‹°ëŠ” í•™ìŠµ ê¸°ë°˜ ì ‘ê·¼ì˜ í™•ì¥ì„±ì„ ê³¼ì†Œí‰ê°€í–ˆìŒ.
>
---

## **ğŸ”Â Methods**

> **âœ…Â ì‚¬ìš©ëœ ì—°êµ¬ ë°©ë²•**
>  supervised learningìœ¼ë¡œ deep CNN í•™ìŠµí•¨. ëª¨ë“  convì™€ FCì— ReLU ì ìš©í•¨. LRN ì‚¬ìš©í•¨. k=2 n=5 alpha=1e-4 beta=0.75ì„. overlapping pooling ì‚¬ìš©í•¨. s<z ì„¤ì •ì„. data augmentation ë‘ ê°€ì§€ ì‚¬ìš©í•¨. random cropê³¼ horizontal flip. RGB-PCA color jitter ì‚¬ìš©í•¨. FC ë‘ ì¸µì— dropout ì ìš©í•¨. 2-GPU model parallel ì‚¬ìš©í•¨. íŠ¹ì • layerì—ì„œë§Œ í†µì‹ í•¨
> 
> **âœ…Â ì‹¤í—˜ ì„¤ê³„**
> ILSVRC-2010ì„ ì£¼ í‰ê°€ë¡œ ì‚¬ìš©í•¨. ILSVRC-2012ì— variant ì œì¶œí•¨. ì§€í‘œëŠ” Top-1ê³¼ Top-5ì„.
> **ğŸ“Â ëª¨ë¸ ë¹„êµ** 
> ë‹¨ì¼ CNNì´ SIFT+FVë³´ë‹¤ ìš°ìˆ˜í•¨. 2-GPU ë¶„í• ë¡œ 1-GPU ëŒ€ë¹„ Top-1 âˆ’1.7pp Top-5 âˆ’1.2pp ê°œì„ ë¨.

---


## **ğŸ”Â Experiments**

> **âœ…Â ë°ì´í„°ì…‹**
> ImageNet LSVRC. 1000 í´ë˜ìŠ¤. train 1.2M. ëŒ€ê·œëª¨ ê³ í•´ìƒë„ ì´ë¯¸ì§€.
> 
> **âœ…Â Models**
> 8 learnable layers, 5 conv 3 FC êµ¬ì„±, ReLU everywhere. LRNì€ conv1ê³¼ conv2 ë’¤ì— ë‘ . max-poolì€ ë‘ LRN ë’¤ì™€ conv5 ë’¤ì— ë‘ . conv1 11Ã—11 stride 4 96ê°œ, conv2 5Ã—5 256ê°œ, conv3 3Ã—3 384ê°œ, conv4 3Ã—3 384ê°œ, conv5 3Ã—3 256ê°œ. FC 4096-4096-1000. ìµœì¢… 1000-way softmax.
> **âœ…Â Evaluation Metrics**
> ILSVC í‘œì¤€, top1, top5 ì‚¬ìš©
> **âœ…Â Implementation Details**
> optimizerëŠ” SGD, batch 128, momentum 0.9, weight decay 0.0005, ì´ˆê¸° lr 0.01, val error ì •ì²´ ì‹œ *0.1ë¡œ ê°ì†Œ. ì•½ 90 epochs í•™ìŠµ. 2Ã—GTX580ìœ¼ë¡œ 5â€“6ì¼ ì†Œìš”. ì¼ë¶€ biasë¥¼ 1ë¡œ ì´ˆê¸°í™”. ReLU í™œì„± ì´ˆê¸°ì— ìœ ë¦¬. test ì‹œ dropout scaling 0.5 ì‚¬ìš©.

---


## **ğŸ“–Â Conclusion**

> **âœ…Â Limitation**
> computeì™€ memory ì œì•½ í¼. ë” í° ëª¨ë¸ê³¼ ë” ê¸´ í•™ìŠµì´ í•„ìš”. videoë¡œ í™•ì¥ í•„ìš”. unsupervised pre-training ì—†ì´ë„ ì„±ëŠ¥ ë‚˜ì™”ìœ¼ë‚˜ compute ì¦ê°€ ì‹œ íš¨ê³¼ ê¸°ëŒ€.
> 
> **âœ…Â Contribution**
> large-scale supervised CNNì˜ ì‹¤íš¨ì„± ì…ì¦. ReLUë¡œ í•™ìŠµ ì†ë„ ê°œì„ . 2-GPU ë³‘ë ¬ë¡œ ëŒ€í˜• ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥. LRNê³¼ overlapping poolingìœ¼ë¡œ generalization í–¥ìƒ. cropê³¼ RGB-PCAë¡œ invariance ê°•í™”. FC dropoutìœ¼ë¡œ overfitting ì–µì œ. ILSVRCì—ì„œ í° í­ì˜ SOTA ê°±ì‹ .

---


## **ğŸ¤”Â Question**

> â„¹ï¸Â *ë³¸ì¸ì´ ìˆ˜í–‰í•œ í•™ìŠµì— ëŒ€í•´ ìŠ¤ìŠ¤ë¡œ ì§ˆë¬¸í•˜ê³  ë‹µí•´ë³´ì„¸ìš”.*
> 
> 
> **ğŸ“Â ì´ ë…¼ë¬¸ì´ ë“±ì¥í•˜ê²Œ ëœ ì´ìœ  + ì´ ë…¼ë¬¸ì´ ê´€ë ¨ Taskì— ê¸°ì—¬í•œ ë‚´ìš©**
> feature engineering ê¸°ë°˜ ì ‘ê·¼ì˜ í™•ì¥ì„± í•œê³„ ìˆì—ˆ. ë°ì´í„°ì™€ computeê°€ ì»¤ì§ˆìˆ˜ë¡ end-to-end learningì´ ìš°ìœ„. ë³¸ ë…¼ë¬¸ì´ ê·¸ ê°€ì„¤ì„ ëŒ€ê·œëª¨ ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦. object classificationì—ì„œ deep CNNì˜ ìœ íš¨ì„±ì„ í™•ë¦½. ì»¤ë®¤ë‹ˆí‹° íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ ì´‰ë°œ.
> **ğŸ“Â ë°°ìš¸ ìˆ˜ ìˆì—ˆë˜ ë‚´ìš©ê³¼ ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì **
> LRNì´ BatchNorm ì‹œëŒ€ì—ë„ ìœ íš¨?
> pre-training ì—†ì´ ë™ì¼ ì„±ëŠ¥ ì¬í˜„ ê°€ëŠ¥?
> 
