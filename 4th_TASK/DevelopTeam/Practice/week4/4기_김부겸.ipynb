{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4242fd90",
   "metadata": {},
   "source": [
    "# XGBoost: 커플 성사 여부 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f509a",
   "metadata": {},
   "source": [
    "`부스팅`: 순차적으로 트리를 만들어 이전 트리로부터 더 나은 트리를 만들어내는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df0ad3",
   "metadata": {},
   "source": [
    "- 랜덤 포레스트보다 훨씬 빠른 속도와 더 좋은 예측 능력을 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a3241c",
   "metadata": {},
   "source": [
    "- 장점\n",
    "    - 예측 속도가 상당히 빠르며, 예측력 또한 좋음\n",
    "    - 변수 종류가 많고 데이터가 클수록 상대적으로 뛰어난 성능을 보여줌\n",
    "- 단점\n",
    "    - 복잡한 모델인 만큼, 해석에 어려움이 있음\n",
    "    - 더 나은 성능을 위한 하이퍼파라미터 튜닝이 까다로움\n",
    "- 유용한 곳\n",
    "    - 종속변수가 연속형 데이터인 경우든 범주형 데이터인 경우든 모두 사용할 수 있음\n",
    "    - 이미지나 자연어가 아닌 표로 정리된 데이터의 경우, 거의 모든 상황에 활용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea22b9",
   "metadata": {},
   "source": [
    "## 10.1 문제 정의: 한눈에 보는 예측 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f7db7",
   "metadata": {},
   "source": [
    "- 종속변수: match(커플 성사 여부)\n",
    "- 평가지표: 정확도, 혼동 행렬, 분류 리포트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1fb2d9",
   "metadata": {},
   "source": [
    "## 10.2 라이브러리 및 데이터 불러오기, 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8460271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>...</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>shared_interests_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Latino/HispanicAmerican</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  gender   age  age_o                                  race  \\\n",
       "0         0  female  21.0   27.0  Asian/PacificIslander/Asian-American   \n",
       "1         0  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "2         1  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "3         0  female  21.0   23.0  Asian/PacificIslander/Asian-American   \n",
       "4         0  female  21.0   24.0  Asian/PacificIslander/Asian-American   \n",
       "\n",
       "                                 race_o  importance_same_race  \\\n",
       "0           European/Caucasian-American                   2.0   \n",
       "1           European/Caucasian-American                   2.0   \n",
       "2  Asian/PacificIslander/Asian-American                   2.0   \n",
       "3           European/Caucasian-American                   2.0   \n",
       "4               Latino/HispanicAmerican                   2.0   \n",
       "\n",
       "   importance_same_religion  pref_o_attractive  pref_o_sincere  ...  \\\n",
       "0                       4.0               35.0            20.0  ...   \n",
       "1                       4.0               60.0             0.0  ...   \n",
       "2                       4.0               19.0            18.0  ...   \n",
       "3                       4.0               30.0             5.0  ...   \n",
       "4                       4.0               30.0            10.0  ...   \n",
       "\n",
       "   funny_partner  ambition_partner  shared_interests_partner  \\\n",
       "0            7.0               6.0                       5.0   \n",
       "1            8.0               5.0                       6.0   \n",
       "2            8.0               5.0                       7.0   \n",
       "3            7.0               6.0                       8.0   \n",
       "4            7.0               6.0                       6.0   \n",
       "\n",
       "   interests_correlate  expected_happy_with_sd_people  \\\n",
       "0                 0.14                            3.0   \n",
       "1                 0.54                            3.0   \n",
       "2                 0.16                            3.0   \n",
       "3                 0.61                            3.0   \n",
       "4                 0.21                            3.0   \n",
       "\n",
       "   expected_num_interested_in_me  like  guess_prob_liked  met  match  \n",
       "0                            2.0   7.0               6.0  0.0      0  \n",
       "1                            2.0   7.0               5.0  1.0      0  \n",
       "2                            2.0   7.0               NaN  1.0      1  \n",
       "3                            2.0   7.0               6.0  0.0      1  \n",
       "4                            2.0   6.0               6.0  0.0      1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "file_url='https://media.githubusercontent.com/media/musthave-ML10/data_source/main/dating.csv'\n",
    "data=pd.read_csv(file_url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2825c49",
   "metadata": {},
   "source": [
    "변수가 39개나 되어 중간에 생략부분이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4af919",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=40 # 40개의 컬럼을 보도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1ac424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>pref_o_ambitious</th>\n",
       "      <th>pref_o_shared_interests</th>\n",
       "      <th>attractive_o</th>\n",
       "      <th>sincere_o</th>\n",
       "      <th>intelligence_o</th>\n",
       "      <th>funny_o</th>\n",
       "      <th>ambitous_o</th>\n",
       "      <th>shared_interests_o</th>\n",
       "      <th>attractive_important</th>\n",
       "      <th>sincere_important</th>\n",
       "      <th>intellicence_important</th>\n",
       "      <th>funny_important</th>\n",
       "      <th>ambtition_important</th>\n",
       "      <th>shared_interests_important</th>\n",
       "      <th>attractive_partner</th>\n",
       "      <th>sincere_partner</th>\n",
       "      <th>intelligence_partner</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>shared_interests_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Latino/HispanicAmerican</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  gender   age  age_o                                  race  \\\n",
       "0         0  female  21.0   27.0  Asian/PacificIslander/Asian-American   \n",
       "1         0  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "2         1  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "3         0  female  21.0   23.0  Asian/PacificIslander/Asian-American   \n",
       "4         0  female  21.0   24.0  Asian/PacificIslander/Asian-American   \n",
       "\n",
       "                                 race_o  importance_same_race  \\\n",
       "0           European/Caucasian-American                   2.0   \n",
       "1           European/Caucasian-American                   2.0   \n",
       "2  Asian/PacificIslander/Asian-American                   2.0   \n",
       "3           European/Caucasian-American                   2.0   \n",
       "4               Latino/HispanicAmerican                   2.0   \n",
       "\n",
       "   importance_same_religion  pref_o_attractive  pref_o_sincere  \\\n",
       "0                       4.0               35.0            20.0   \n",
       "1                       4.0               60.0             0.0   \n",
       "2                       4.0               19.0            18.0   \n",
       "3                       4.0               30.0             5.0   \n",
       "4                       4.0               30.0            10.0   \n",
       "\n",
       "   pref_o_intelligence  pref_o_funny  pref_o_ambitious  \\\n",
       "0                 20.0          20.0               0.0   \n",
       "1                  0.0          40.0               0.0   \n",
       "2                 19.0          18.0              14.0   \n",
       "3                 15.0          40.0               5.0   \n",
       "4                 20.0          10.0              10.0   \n",
       "\n",
       "   pref_o_shared_interests  attractive_o  sincere_o  intelligence_o  funny_o  \\\n",
       "0                      5.0           6.0        8.0             8.0      8.0   \n",
       "1                      0.0           7.0        8.0            10.0      7.0   \n",
       "2                     12.0          10.0       10.0            10.0     10.0   \n",
       "3                      5.0           7.0        8.0             9.0      8.0   \n",
       "4                     20.0           8.0        7.0             9.0      6.0   \n",
       "\n",
       "   ambitous_o  shared_interests_o  attractive_important  sincere_important  \\\n",
       "0         8.0                 6.0                  15.0               20.0   \n",
       "1         7.0                 5.0                  15.0               20.0   \n",
       "2        10.0                10.0                  15.0               20.0   \n",
       "3         9.0                 8.0                  15.0               20.0   \n",
       "4         9.0                 7.0                  15.0               20.0   \n",
       "\n",
       "   intellicence_important  funny_important  ambtition_important  \\\n",
       "0                    20.0             15.0                 15.0   \n",
       "1                    20.0             15.0                 15.0   \n",
       "2                    20.0             15.0                 15.0   \n",
       "3                    20.0             15.0                 15.0   \n",
       "4                    20.0             15.0                 15.0   \n",
       "\n",
       "   shared_interests_important  attractive_partner  sincere_partner  \\\n",
       "0                        15.0                 6.0              9.0   \n",
       "1                        15.0                 7.0              8.0   \n",
       "2                        15.0                 5.0              8.0   \n",
       "3                        15.0                 7.0              6.0   \n",
       "4                        15.0                 5.0              6.0   \n",
       "\n",
       "   intelligence_partner  funny_partner  ambition_partner  \\\n",
       "0                   7.0            7.0               6.0   \n",
       "1                   7.0            8.0               5.0   \n",
       "2                   9.0            8.0               5.0   \n",
       "3                   8.0            7.0               6.0   \n",
       "4                   7.0            7.0               6.0   \n",
       "\n",
       "   shared_interests_partner  interests_correlate  \\\n",
       "0                       5.0                 0.14   \n",
       "1                       6.0                 0.54   \n",
       "2                       7.0                 0.16   \n",
       "3                       8.0                 0.61   \n",
       "4                       6.0                 0.21   \n",
       "\n",
       "   expected_happy_with_sd_people  expected_num_interested_in_me  like  \\\n",
       "0                            3.0                            2.0   7.0   \n",
       "1                            3.0                            2.0   7.0   \n",
       "2                            3.0                            2.0   7.0   \n",
       "3                            3.0                            2.0   7.0   \n",
       "4                            3.0                            2.0   6.0   \n",
       "\n",
       "   guess_prob_liked  met  match  \n",
       "0               6.0  0.0      0  \n",
       "1               5.0  1.0      0  \n",
       "2               NaN  1.0      1  \n",
       "3               6.0  0.0      1  \n",
       "4               6.0  0.0      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # 전부 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00b5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 39 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   has_null                       8378 non-null   int64  \n",
      " 1   gender                         8378 non-null   object \n",
      " 2   age                            8283 non-null   float64\n",
      " 3   age_o                          8274 non-null   float64\n",
      " 4   race                           8315 non-null   object \n",
      " 5   race_o                         8305 non-null   object \n",
      " 6   importance_same_race           8299 non-null   float64\n",
      " 7   importance_same_religion       8299 non-null   float64\n",
      " 8   pref_o_attractive              8289 non-null   float64\n",
      " 9   pref_o_sincere                 8289 non-null   float64\n",
      " 10  pref_o_intelligence            8289 non-null   float64\n",
      " 11  pref_o_funny                   8280 non-null   float64\n",
      " 12  pref_o_ambitious               8271 non-null   float64\n",
      " 13  pref_o_shared_interests        8249 non-null   float64\n",
      " 14  attractive_o                   8166 non-null   float64\n",
      " 15  sincere_o                      8091 non-null   float64\n",
      " 16  intelligence_o                 8072 non-null   float64\n",
      " 17  funny_o                        8018 non-null   float64\n",
      " 18  ambitous_o                     7656 non-null   float64\n",
      " 19  shared_interests_o             7302 non-null   float64\n",
      " 20  attractive_important           8299 non-null   float64\n",
      " 21  sincere_important              8299 non-null   float64\n",
      " 22  intellicence_important         8299 non-null   float64\n",
      " 23  funny_important                8289 non-null   float64\n",
      " 24  ambtition_important            8279 non-null   float64\n",
      " 25  shared_interests_important     8257 non-null   float64\n",
      " 26  attractive_partner             8176 non-null   float64\n",
      " 27  sincere_partner                8101 non-null   float64\n",
      " 28  intelligence_partner           8082 non-null   float64\n",
      " 29  funny_partner                  8028 non-null   float64\n",
      " 30  ambition_partner               7666 non-null   float64\n",
      " 31  shared_interests_partner       7311 non-null   float64\n",
      " 32  interests_correlate            8220 non-null   float64\n",
      " 33  expected_happy_with_sd_people  8277 non-null   float64\n",
      " 34  expected_num_interested_in_me  1800 non-null   float64\n",
      " 35  like                           8138 non-null   float64\n",
      " 36  guess_prob_liked               8069 non-null   float64\n",
      " 37  met                            8003 non-null   float64\n",
      " 38  match                          8378 non-null   int64  \n",
      "dtypes: float64(34), int64(2), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ad4f8",
   "metadata": {},
   "source": [
    "- has_null: Null값이 있는지 여부\n",
    "- age/age_o: age는 본인 나이, age_o는 상대방 나이\n",
    "- race/race_o: 인종/상대인종\n",
    "- importance_same_race/importance_same_religion: 인종과 종교를 중요시 여기는지에 대한 응답\n",
    "- attractive, sincere, intelligence, funny, ambitious, shared_interests: 4가지 관점에서 평가된 항목\n",
    "    - pref_o_xxx: 상대방이 해당항목을 얼마나 중요하게 생각하는가에 대한 응답\n",
    "    - xxx_0: 상대방이 본인에 대한 해당 항목을 평가한 항목\n",
    "    - xxx_important: 해당 항목에 대해 본인이 얼마나 중요하게 생각하는가에 대한 응답\n",
    "    - xxx_partner: 본인이 상대방에 대한 해당 항목을 평가한 항목\n",
    "- interests_correlate: 관심사 연관도\n",
    "- expeceted_happy_with_sd_people: 스피드 데이팅을 통해 만난 사람과 함께할 때 얼마나 좋은지에 대한 기대치\n",
    "- expected_num_interested_in_me: 얼마나 많은 사람이 나에게 관심을 보일지에 대한 기대치\n",
    "- like: 파트너가 마음에 들었는지 여부\n",
    "- guess_prob_liked: 파트너가 나를 마음에 들어했을지에 대한 예상\n",
    "- met: 파트너를 스피드 데이팅 이벤트 이전에 만난 적이 있는지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea14b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>pref_o_ambitious</th>\n",
       "      <th>pref_o_shared_interests</th>\n",
       "      <th>attractive_o</th>\n",
       "      <th>sincere_o</th>\n",
       "      <th>intelligence_o</th>\n",
       "      <th>funny_o</th>\n",
       "      <th>ambitous_o</th>\n",
       "      <th>shared_interests_o</th>\n",
       "      <th>attractive_important</th>\n",
       "      <th>sincere_important</th>\n",
       "      <th>intellicence_important</th>\n",
       "      <th>funny_important</th>\n",
       "      <th>ambtition_important</th>\n",
       "      <th>shared_interests_important</th>\n",
       "      <th>attractive_partner</th>\n",
       "      <th>sincere_partner</th>\n",
       "      <th>intelligence_partner</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>shared_interests_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8378.00</td>\n",
       "      <td>8283.00</td>\n",
       "      <td>8274.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8280.00</td>\n",
       "      <td>8271.00</td>\n",
       "      <td>8249.00</td>\n",
       "      <td>8166.00</td>\n",
       "      <td>8091.00</td>\n",
       "      <td>8072.00</td>\n",
       "      <td>8018.00</td>\n",
       "      <td>7656.00</td>\n",
       "      <td>7302.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8279.00</td>\n",
       "      <td>8257.00</td>\n",
       "      <td>8176.00</td>\n",
       "      <td>8101.00</td>\n",
       "      <td>8082.00</td>\n",
       "      <td>8028.00</td>\n",
       "      <td>7666.00</td>\n",
       "      <td>7311.00</td>\n",
       "      <td>8220.00</td>\n",
       "      <td>8277.00</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>8138.00</td>\n",
       "      <td>8069.00</td>\n",
       "      <td>8003.00</td>\n",
       "      <td>8378.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.87</td>\n",
       "      <td>26.36</td>\n",
       "      <td>26.36</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.65</td>\n",
       "      <td>22.50</td>\n",
       "      <td>17.40</td>\n",
       "      <td>20.27</td>\n",
       "      <td>17.46</td>\n",
       "      <td>10.69</td>\n",
       "      <td>11.85</td>\n",
       "      <td>6.19</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.37</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.78</td>\n",
       "      <td>5.47</td>\n",
       "      <td>22.51</td>\n",
       "      <td>17.40</td>\n",
       "      <td>20.27</td>\n",
       "      <td>17.46</td>\n",
       "      <td>10.68</td>\n",
       "      <td>11.85</td>\n",
       "      <td>6.19</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.37</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.78</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.53</td>\n",
       "      <td>5.57</td>\n",
       "      <td>6.13</td>\n",
       "      <td>5.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.33</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.81</td>\n",
       "      <td>12.57</td>\n",
       "      <td>7.04</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.16</td>\n",
       "      <td>12.59</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.73</td>\n",
       "      <td>4.76</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.39</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.39</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.37</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.18</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_null      age    age_o  importance_same_race  \\\n",
       "count   8378.00  8283.00  8274.00               8299.00   \n",
       "mean       0.87    26.36    26.36                  3.78   \n",
       "std        0.33     3.57     3.56                  2.85   \n",
       "min        0.00    18.00    18.00                  0.00   \n",
       "25%        1.00    24.00    24.00                  1.00   \n",
       "50%        1.00    26.00    26.00                  3.00   \n",
       "75%        1.00    28.00    28.00                  6.00   \n",
       "max        1.00    55.00    55.00                 10.00   \n",
       "\n",
       "       importance_same_religion  pref_o_attractive  pref_o_sincere  \\\n",
       "count                   8299.00            8289.00         8289.00   \n",
       "mean                       3.65              22.50           17.40   \n",
       "std                        2.81              12.57            7.04   \n",
       "min                        1.00               0.00            0.00   \n",
       "25%                        1.00              15.00           15.00   \n",
       "50%                        3.00              20.00           18.37   \n",
       "75%                        6.00              25.00           20.00   \n",
       "max                       10.00             100.00           60.00   \n",
       "\n",
       "       pref_o_intelligence  pref_o_funny  pref_o_ambitious  \\\n",
       "count              8289.00       8280.00           8271.00   \n",
       "mean                 20.27         17.46             10.69   \n",
       "std                   6.78          6.09              6.13   \n",
       "min                   0.00          0.00              0.00   \n",
       "25%                  17.39         15.00              5.00   \n",
       "50%                  20.00         18.00             10.00   \n",
       "75%                  23.81         20.00             15.00   \n",
       "max                  50.00         50.00             53.00   \n",
       "\n",
       "       pref_o_shared_interests  attractive_o  sincere_o  intelligence_o  \\\n",
       "count                  8249.00       8166.00    8091.00         8072.00   \n",
       "mean                     11.85          6.19       7.18            7.37   \n",
       "std                       6.36          1.95       1.74            1.55   \n",
       "min                       0.00          0.00       0.00            0.00   \n",
       "25%                       9.52          5.00       6.00            6.00   \n",
       "50%                      10.64          6.00       7.00            7.00   \n",
       "75%                      16.00          8.00       8.00            8.00   \n",
       "max                      30.00         10.50      10.00           10.00   \n",
       "\n",
       "       funny_o  ambitous_o  shared_interests_o  attractive_important  \\\n",
       "count  8018.00     7656.00             7302.00               8299.00   \n",
       "mean      6.40        6.78                5.47                 22.51   \n",
       "std       1.95        1.79                2.16                 12.59   \n",
       "min       0.00        0.00                0.00                  0.00   \n",
       "25%       5.00        6.00                4.00                 15.00   \n",
       "50%       7.00        7.00                6.00                 20.00   \n",
       "75%       8.00        8.00                7.00                 25.00   \n",
       "max      11.00       10.00               10.00                100.00   \n",
       "\n",
       "       sincere_important  intellicence_important  funny_important  \\\n",
       "count            8299.00                 8299.00          8289.00   \n",
       "mean               17.40                   20.27            17.46   \n",
       "std                 7.05                    6.78             6.09   \n",
       "min                 0.00                    0.00             0.00   \n",
       "25%                15.00                   17.39            15.00   \n",
       "50%                18.18                   20.00            18.00   \n",
       "75%                20.00                   23.81            20.00   \n",
       "max                60.00                   50.00            50.00   \n",
       "\n",
       "       ambtition_important  shared_interests_important  attractive_partner  \\\n",
       "count              8279.00                     8257.00             8176.00   \n",
       "mean                 10.68                       11.85                6.19   \n",
       "std                   6.12                        6.36                1.95   \n",
       "min                   0.00                        0.00                0.00   \n",
       "25%                   5.00                        9.52                5.00   \n",
       "50%                  10.00                       10.64                6.00   \n",
       "75%                  15.00                       16.00                8.00   \n",
       "max                  53.00                       30.00               10.00   \n",
       "\n",
       "       sincere_partner  intelligence_partner  funny_partner  ambition_partner  \\\n",
       "count          8101.00               8082.00        8028.00           7666.00   \n",
       "mean              7.18                  7.37           6.40              6.78   \n",
       "std               1.74                  1.55           1.95              1.79   \n",
       "min               0.00                  0.00           0.00              0.00   \n",
       "25%               6.00                  6.00           5.00              6.00   \n",
       "50%               7.00                  7.00           7.00              7.00   \n",
       "75%               8.00                  8.00           8.00              8.00   \n",
       "max              10.00                 10.00          10.00             10.00   \n",
       "\n",
       "       shared_interests_partner  interests_correlate  \\\n",
       "count                   7311.00              8220.00   \n",
       "mean                       5.47                 0.20   \n",
       "std                        2.16                 0.30   \n",
       "min                        0.00                -0.83   \n",
       "25%                        4.00                -0.02   \n",
       "50%                        6.00                 0.21   \n",
       "75%                        7.00                 0.43   \n",
       "max                       10.00                 0.91   \n",
       "\n",
       "       expected_happy_with_sd_people  expected_num_interested_in_me     like  \\\n",
       "count                        8277.00                        1800.00  8138.00   \n",
       "mean                            5.53                           5.57     6.13   \n",
       "std                             1.73                           4.76     1.84   \n",
       "min                             1.00                           0.00     0.00   \n",
       "25%                             5.00                           2.00     5.00   \n",
       "50%                             6.00                           4.00     6.00   \n",
       "75%                             7.00                           8.00     7.00   \n",
       "max                            10.00                          20.00    10.00   \n",
       "\n",
       "       guess_prob_liked      met    match  \n",
       "count           8069.00  8003.00  8378.00  \n",
       "mean               5.21     0.05     0.16  \n",
       "std                2.13     0.28     0.37  \n",
       "min                0.00     0.00     0.00  \n",
       "25%                4.00     0.00     0.00  \n",
       "50%                5.00     0.00     0.00  \n",
       "75%                7.00     0.00     0.00  \n",
       "max               10.00     8.00     1.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.describe(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1a108",
   "metadata": {},
   "source": [
    "각 데이터의 최댓값이 다른 것으로 보아 데이터 수집방식 확인\n",
    "\n",
    "중요도 관련 변수는 총 100점으로 각 항목에 분배해 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66233fbe",
   "metadata": {},
   "source": [
    "## 10.3 전처리: 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1bbb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_null                         0.000000\n",
       "gender                           0.000000\n",
       "age                              0.011339\n",
       "age_o                            0.012413\n",
       "race                             0.007520\n",
       "race_o                           0.008713\n",
       "importance_same_race             0.009429\n",
       "importance_same_religion         0.009429\n",
       "pref_o_attractive                0.010623\n",
       "pref_o_sincere                   0.010623\n",
       "pref_o_intelligence              0.010623\n",
       "pref_o_funny                     0.011697\n",
       "pref_o_ambitious                 0.012772\n",
       "pref_o_shared_interests          0.015397\n",
       "attractive_o                     0.025304\n",
       "sincere_o                        0.034256\n",
       "intelligence_o                   0.036524\n",
       "funny_o                          0.042970\n",
       "ambitous_o                       0.086178\n",
       "shared_interests_o               0.128432\n",
       "attractive_important             0.009429\n",
       "sincere_important                0.009429\n",
       "intellicence_important           0.009429\n",
       "funny_important                  0.010623\n",
       "ambtition_important              0.011817\n",
       "shared_interests_important       0.014443\n",
       "attractive_partner               0.024111\n",
       "sincere_partner                  0.033063\n",
       "intelligence_partner             0.035331\n",
       "funny_partner                    0.041776\n",
       "ambition_partner                 0.084984\n",
       "shared_interests_partner         0.127357\n",
       "interests_correlate              0.018859\n",
       "expected_happy_with_sd_people    0.012055\n",
       "expected_num_interested_in_me    0.785152\n",
       "like                             0.028646\n",
       "guess_prob_liked                 0.036882\n",
       "met                              0.044760\n",
       "match                            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f370ce",
   "metadata": {},
   "source": [
    "대부분 결측치가 5% 미만\n",
    "- XGBoost는 기본적으로 트리 베이스 모델이라 결측치를 채우기는 까다롭지 않음\n",
    "- 중요도와 관련된 변수만 결측치 제거\n",
    "    - 후에 중요도 X 점수 로 계산하기 때문\n",
    "- 나머지는 의미없는 값인 -99로 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45100c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna(subset=['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny',\n",
    "                        'pref_o_ambitious', 'pref_o_shared_interests', 'attractive_important',\n",
    "                        'sincere_important', 'intellicence_important', 'funny_important',\n",
    "                         'ambtition_important', 'shared_interests_important'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd7dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.fillna(-99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31332b",
   "metadata": {},
   "source": [
    "## 10.4 전처리: 피퍼 엔지니어링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fba20",
   "metadata": {},
   "source": [
    "나이차를 계산하기 위해 -99로 결측치 채운 값을 주의해야함\n",
    "\n",
    "남자가 여자보다 많은지를 고려하기위해 성별도 생각해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02cf3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_gap(x):\n",
    "    if x['age']==-99:\n",
    "        return -99\n",
    "    elif x['age_o']==-99:\n",
    "        return -99\n",
    "    elif x['gender']=='female':\n",
    "        return x['age_o']-x['age']\n",
    "    else:\n",
    "        return x['age']-x['age_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad107818",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_gap']=data.apply(age_gap,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdd7af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_gap_abs']=abs(data['age_gap']) # 절댓값 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ffa5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_race(x):\n",
    "    if x['race']==-99:\n",
    "        return -99\n",
    "    elif x['race_o']==-99:\n",
    "        return -99\n",
    "    elif x['race']==x['race_o']:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1 # 나중에 크기를 확인하기 위해 0대신 -1을 사용\n",
    "    \n",
    "data['same_race']=data.apply(same_race, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9df5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_race_point(x):\n",
    "    if x['same_race']==-99:\n",
    "        return -99\n",
    "    else:\n",
    "        return x['same_race'] * x['importance_same_race']\n",
    "    \n",
    "data['same_race_point']=data.apply(same_race_point, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa6f96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(data, importance, score):\n",
    "    if data[importance] == -99:\n",
    "        return -99\n",
    "    elif data[score] == -99:\n",
    "        return -99\n",
    "    else:\n",
    "        return data[importance] * data[score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250ac3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
       "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[8:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c67560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_imp=data.columns[8:14] # 상대방의 중요도\n",
    "partner_rate_me=data.columns[14:20] # 본인에 대한 상대방의 평가\n",
    "my_imp=data.columns[20:26] # 본인의 중요도\n",
    "my_rate_partner=data.columns[26:32] # 상대방에 대한 본인의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896c6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_partner=['attractive_p', 'sincere_partner_p', 'intelligence_p', 'funny_p', 'ambition_p', 'shared_interests_p']\n",
    "\n",
    "new_label_me=['attractive_m', 'sincere_partner_m', 'intelligence_m', 'funny_m', 'ambition_m', 'shared_interests_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f939a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중요도 * 평가\n",
    "for i,j,k in zip(new_label_partner, partner_imp, partner_rate_me):\n",
    "    data[i]=data.apply(lambda x: rating(x,j,k), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d33a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j,k in zip(new_label_me, my_imp, my_rate_partner):\n",
    "    data[i]=data.apply(lambda x: rating(x,j,k), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0088cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object형 더미변수로 변환\n",
    "data=pd.get_dummies(data,columns=['gender', 'race', 'race_o'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc036ed0",
   "metadata": {},
   "source": [
    "## 10.5 모델링 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7904f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('match', axis=1), data['match'], test_size=0.2, random_state=100)\n",
    "\n",
    "import xgboost as xgb\n",
    "model=xgb.XGBClassifier(n_estimators=500, max_depth=5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7a78816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boo\\anaconda3\\envs\\py36\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=500, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29b95a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8616236162361623"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfc5d0",
   "metadata": {},
   "source": [
    "모델링 없이 모든 경우를 0으로만 해도 84%의 성능이 나오므로 좋은 결과가 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51468571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1291   74]\n",
      " [ 151  110]]\n"
     ]
    }
   ],
   "source": [
    "print((confusion_matrix(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aad96295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1365\n",
      "           1       0.60      0.42      0.49       261\n",
      "\n",
      "    accuracy                           0.86      1626\n",
      "   macro avg       0.75      0.68      0.71      1626\n",
      "weighted avg       0.85      0.86      0.85      1626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67aa09d",
   "metadata": {},
   "source": [
    "위 두 표는 책과 다르게 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85966795",
   "metadata": {},
   "source": [
    "0에 대한 예측에 비해 1에 대한 예측이 낮게 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58136e75",
   "metadata": {},
   "source": [
    "## 10.6 이해하기: 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349fdc0",
   "metadata": {},
   "source": [
    "`경사하강법`: 머신러닝이 학습시킬 때 최소의 오차를 찾는 방법\n",
    "- 오차 함수에 대한 경사도를 기준으로 매개변수를 반복적으로 이동해가며 최소 오차를 찾음\n",
    "- 오차 함수의 미분 계수(기울기)가 0을 찾는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5b434",
   "metadata": {},
   "source": [
    "- `지역 최솟값`: 기울기가 0인 지점이지만 전체범위에서 최솟값이 아님\n",
    "- `전역 최솟값`: 전체 범위에서 가장 작은 값을 가지며 기울기가 0인 지점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4d35d",
   "metadata": {},
   "source": [
    "## 10.7 하이퍼파라미터 튜닝: 그리드 서치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029d17b0",
   "metadata": {},
   "source": [
    "`그리드 서치`: 하이퍼파라미터 후보들을 입력해 각 조합에 대해 모델링해보고 최적의 조합을 알려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ef126cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3], # 보폭의 크기\n",
    "    'max_depth': [5, 7, 10], # 각 트리의 깊이를 제한\n",
    "    'subsample': [0.5, 0.7, 1], # 데이터의 일부만 사용\n",
    "    'n_estimators': [300, 500, 1000] # 전체 나무의 개수를 정함\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36f9518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f14c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = GridSearchCV(model, parameters, n_jobs=-1, scoring='f1', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74824c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model.fit(X_train, y_train) #너무 오래걸려 실행 중단함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeeab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaedb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=gs_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18c589",
   "metadata": {},
   "source": [
    "## 10.8 중요 변수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5867f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boo\\anaconda3\\envs\\py36\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.3, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=1000, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=xgb.XGBClassifier(learning_rate=0.3, max_depth=5, n_estimators=1000, subsample=0.5, random_state=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0ba9911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02178125, 0.01137641, 0.00998134, 0.00984809, 0.01060789,\n",
       "       0.01359383, 0.01065769, 0.01713987, 0.01186322, 0.01206678,\n",
       "       0.01331671, 0.04854793, 0.01233603, 0.01430371, 0.02732428,\n",
       "       0.01440853, 0.02333124, 0.01437325, 0.01104851, 0.01472255,\n",
       "       0.00973702, 0.01481565, 0.01001215, 0.02409385, 0.01538233,\n",
       "       0.01472   , 0.02749152, 0.01478216, 0.01670052, 0.01100918,\n",
       "       0.0106856 , 0.02170104, 0.04928579, 0.01951623, 0.03824322,\n",
       "       0.01167233, 0.01354653, 0.01223037, 0.01456301, 0.0113123 ,\n",
       "       0.01188447, 0.01298039, 0.01511254, 0.01037562, 0.01001647,\n",
       "       0.01314105, 0.01188815, 0.01242248, 0.01119815, 0.01119024,\n",
       "       0.0116582 , 0.00895496, 0.01707342, 0.01282681, 0.03765631,\n",
       "       0.02832991, 0.03117039, 0.01136704, 0.02328539, 0.0133381 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "072ff436",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame({'features': X_train.columns, 'values':model.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce77f60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>has_null</td>\n",
       "      <td>0.021781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>0.011376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_o</td>\n",
       "      <td>0.009981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>importance_same_race</td>\n",
       "      <td>0.009848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>importance_same_religion</td>\n",
       "      <td>0.010608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   features    values\n",
       "0                  has_null  0.021781\n",
       "1                       age  0.011376\n",
       "2                     age_o  0.009981\n",
       "3      importance_same_race  0.009848\n",
       "4  importance_same_religion  0.010608"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9e2b0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='values', ylabel='features'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(x='values', y='features', data=feature_imp.sort_values(by='values', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786f88e0",
   "metadata": {},
   "source": [
    "## 10.9 이해하기:  XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b0b21",
   "metadata": {},
   "source": [
    "결정 트리 -> 배깅 -> 랜덤 포레스트 -> 부스팅 -> 경사 부스팅 -> XG 부스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e964d",
   "metadata": {},
   "source": [
    "### 배깅\n",
    "\n",
    "부트스트랩 훈련셋을 사용하는 트리 모델\n",
    "> 부트스트랩: 데이터의 일부분을 무작위로 반복 추출하는 방법\n",
    "- 오버피팅을 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b382e",
   "metadata": {},
   "source": [
    "### 부스팅과 에이다 부스팅\n",
    "`부스팅`: 랜덤 포레스트에서 한 단계 더 발전한 방법\n",
    "- 랜덤 포레스트는 각 트리가 독립적, 부스팅은 그렇지 않음\n",
    "- 부스팅은 각 트리를 순차적으로 만들면서 이전 트리의 정보를 이용\n",
    "\n",
    "`에이다 부스트`: 부스팅의 대표 알고리즘\n",
    "- 단계적으로 트리를 만들 때 이전 단계에서의 분류 결과에 따라 각 데이터에 가중치를 부여/수정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249d760",
   "metadata": {},
   "source": [
    "### 경사 부스팅과 XGBoost\n",
    "\n",
    "`경사부스팅`: 경사하강법을 이용하여 이전 모델의 에러를 기반으로 다음 트리를 만들어감\n",
    "\n",
    "`XGBoost`: 경사 부스팅보다 계싼 성능 최적화와 알고리즘 개선을 함께 이룬 모델\n",
    "- 2차 도함수를 활용해 더 적적한 이동 방향과 이동 크기를 찾아내어 더 빠른 시간에 전역 최솟값에 달함\n",
    "- 정규화 하이퍼파라미터 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c1437",
   "metadata": {},
   "source": [
    "# 질문\n",
    "\n",
    "`Chaper 10` : GridSearch를 사용했을 때 코드 실행이 오래걸립니다. 이러한 경우에 GridSearch와 비슷한 성능을 내면서 시간적 비용에서 더 좋은 결과를 보여주는 방식으로 어떠한 것이 있는지 궁금합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23872ac5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
